name: Run Scraper Every 3 Hours

on:
  schedule:
    - cron: '0 */3 * * *'  # This cron expression runs every 3 hours
  workflow_dispatch:  # This allows you to manually trigger the workflow from the GitHub UI

jobs:
  scraper:
    runs-on: ubuntu-latest  # GitHub will use an Ubuntu environment to run this job
    
    steps:
      # Step 1: Checkout the repository code
      - name: Checkout repository
        uses: actions/checkout@v2
        
      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'  # Set your desired Python version
    
      # Step 3: Install required dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager  # Add other dependencies as needed

      # Step 4: Run the scraper script
      - name: Run scraper
        run: |
          python scraper.py  # Ensure this is the correct path to your scraper script

      # Optional Step 5: Commit and push new CSV data (if you want to update the file in the repository)
      - name: Commit new data
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add ebay_tech_deals.csv
          git commit -m "Update ebay_tech_deals.csv from scraper"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # GitHub token for authentication
